"""
Classe de base pour les agents sp√©cialis√©s.
Phase 3 du plan d'√©volution Ecrituria v2.0
"""
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, TypedDict
from dataclasses import dataclass, field
from enum import Enum
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
import os
from dotenv import load_dotenv

load_dotenv()


class AgentType(Enum):
    """Types d'agents disponibles."""
    RECHERCHEUR = "rechercheur"
    COHERENCE = "coherence"
    CREATIF = "creatif"
    EDITEUR = "editeur"
    ANALYSTE = "analyste"


class AgentState(TypedDict, total=False):
    """√âtat partag√© entre les agents dans un workflow."""
    # Entr√©e
    question: str
    project_name: str
    
    # Contexte r√©cup√©r√©
    documents: List[Document]
    graph_context: Dict[str, Any]
    
    # Analyse
    detected_entities: List[str]
    question_type: str  # factual, creative, analysis, coherence
    
    # R√©sultats interm√©diaires
    search_results: Dict[str, Any]
    coherence_issues: List[Dict[str, Any]]
    creative_suggestions: List[str]
    
    # Sortie finale
    answer: str
    sources: List[str]
    confidence: float
    agent_chain: List[str]  # Agents qui ont particip√©


@dataclass
class AgentResponse:
    """R√©ponse d'un agent."""
    content: str
    agent_type: AgentType
    confidence: float = 1.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    sources: List[str] = field(default_factory=list)
    
    def to_dict(self) -> dict:
        return {
            "content": self.content,
            "agent": self.agent_type.value,
            "confidence": self.confidence,
            "metadata": self.metadata,
            "sources": self.sources
        }


class BaseAgent(ABC):
    """
    Classe de base pour tous les agents.
    
    Chaque agent sp√©cialis√© h√©rite de cette classe et impl√©mente
    sa logique sp√©cifique dans la m√©thode process().
    """
    
    agent_type: AgentType = None
    description: str = "Agent de base"
    
    def __init__(
        self,
        project_name: str,
        model: str = "gpt-4o-mini",
        use_openrouter: bool = True,
        temperature: float = 0.7
    ):
        """
        Initialise l'agent.
        
        Args:
            project_name: Nom du projet
            model: Mod√®le LLM √† utiliser
            use_openrouter: Utiliser OpenRouter
            temperature: Temp√©rature de g√©n√©ration
        """
        self.project_name = project_name
        self.model = model
        self.temperature = temperature
        
        # Cr√©er le LLM
        if use_openrouter:
            self.llm = ChatOpenAI(
                model=model,
                temperature=temperature,
                base_url="https://openrouter.ai/api/v1",
                default_headers={
                    "HTTP-Referer": "https://github.com/fiction-assistant",
                    "X-Title": "Fiction Assistant RAG"
                }
            )
        else:
            self.llm = ChatOpenAI(model=model, temperature=temperature)
        
        # Composants optionnels (lazy loading)
        self._rag_engine = None
        self._graph_engine = None
    
    @property
    def rag_engine(self):
        """Lazy loading du moteur RAG."""
        if self._rag_engine is None:
            from src.rag import RAGEngine
            self._rag_engine = RAGEngine(
                self.project_name,
                model=self.model,
                use_hybrid_search=True,
                use_reranking=True
            )
        return self._rag_engine
    
    @property
    def graph_engine(self):
        """Lazy loading du moteur GraphRAG."""
        if self._graph_engine is None:
            from src.graph.graph_rag import GraphRAGEngine
            self._graph_engine = GraphRAGEngine(
                self.project_name,
                model=self.model
            )
        return self._graph_engine
    
    @abstractmethod
    def process(self, state: AgentState) -> AgentState:
        """
        Traite l'√©tat et retourne l'√©tat mis √† jour.
        
        Args:
            state: √âtat actuel du workflow
            
        Returns:
            √âtat mis √† jour
        """
        pass
    
    def should_run(self, state: AgentState) -> bool:
        """
        D√©termine si cet agent doit s'ex√©cuter.
        
        Args:
            state: √âtat actuel
            
        Returns:
            True si l'agent doit s'ex√©cuter
        """
        return True
    
    def invoke_llm(self, prompt: str) -> str:
        """
        Invoque le LLM avec un prompt.
        
        Args:
            prompt: Prompt √† envoyer
            
        Returns:
            R√©ponse du LLM
        """
        response = self.llm.invoke(prompt)
        return response.content if hasattr(response, 'content') else str(response)
    
    def retrieve_context(
        self,
        query: str,
        k: int = 5,
        use_graph: bool = True
    ) -> Dict[str, Any]:
        """
        R√©cup√®re le contexte pertinent pour une requ√™te.
        
        Args:
            query: Requ√™te de recherche
            k: Nombre de documents
            use_graph: Utiliser aussi le graphe
            
        Returns:
            Dict avec documents et contexte graphe
        """
        context = {
            "documents": [],
            "graph_context": {}
        }
        
        # Recherche vectorielle
        try:
            context["documents"] = self.rag_engine.retrieve(query, k=k)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur recherche vectorielle: {e}")
        
        # Contexte du graphe
        if use_graph:
            try:
                entity_ids = self.graph_engine.extract_question_entities(query)
                context["graph_context"] = self.graph_engine.get_graph_context(entity_ids)
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur contexte graphe: {e}")
        
        return context
    
    def format_documents_context(self, documents: List[Document]) -> str:
        """Formate les documents en contexte textuel."""
        if not documents:
            return "Aucun document pertinent trouv√©."
        
        parts = []
        for i, doc in enumerate(documents, 1):
            source = doc.metadata.get('relative_path', f'doc_{i}')
            parts.append(f"[{i}. {source}]\n{doc.page_content}")
        
        return "\n\n---\n\n".join(parts)
    
    def classify_question(self, question: str) -> str:
        """
        Classifie le type de question.
        
        Args:
            question: Question √† classifier
            
        Returns:
            Type: "factual", "creative", "analysis", "coherence"
        """
        prompt = f"""Classifie cette question dans une des cat√©gories suivantes:
- factual: Question sur des faits de l'univers (qui, quoi, o√π, quand)
- creative: Demande de g√©n√©ration de contenu (sc√®ne, dialogue, id√©e)
- analysis: Demande d'analyse (structure, th√®mes, arcs narratifs)
- coherence: V√©rification de coh√©rence ou recherche d'incoh√©rences

Question: {question}

R√©ponds avec UN SEUL mot (factual, creative, analysis, ou coherence):"""
        
        response = self.invoke_llm(prompt).lower().strip()
        
        # Valider la r√©ponse
        valid_types = ["factual", "creative", "analysis", "coherence"]
        for t in valid_types:
            if t in response:
                return t
        
        return "factual"  # D√©faut
    
    def __repr__(self):
        return f"<{self.__class__.__name__} project='{self.project_name}'>"


class DummyAgent(BaseAgent):
    """Agent de test qui ne fait rien."""
    
    agent_type = AgentType.RECHERCHEUR
    description = "Agent de test"
    
    def process(self, state: AgentState) -> AgentState:
        state["agent_chain"] = state.get("agent_chain", []) + [self.agent_type.value]
        return state


# Test du module
if __name__ == "__main__":
    print("\nü§ñ Test de la classe BaseAgent")
    print("=" * 50)
    
    # Cr√©er un agent de test
    agent = DummyAgent("anomalie2084")
    print(f"Agent cr√©√©: {agent}")
    
    # Tester la classification
    questions = [
        "Qui est Alex Chen?",
        "√âcris une sc√®ne de combat entre Alex et Voss",
        "Analyse la structure narrative de la saison 1",
        "Y a-t-il des incoh√©rences dans le worldbuilding?"
    ]
    
    print("\nüìù Classification des questions:")
    for q in questions:
        try:
            q_type = agent.classify_question(q)
            print(f"   [{q_type:10}] {q[:50]}...")
        except Exception as e:
            print(f"   [error] {q[:50]}... ({e})")
    
    print("\n‚úÖ Test r√©ussi!")

